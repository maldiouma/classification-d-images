# D√©tection et classification d‚Äôimages m√©dicales par transfert d‚Äôapprentissage

## Objectif
Ce projet vise √† classifier des images m√©dicales (binaire ou multi-classes) en utilisant le transfert d‚Äôapprentissage avec ResNet18/50, la data augmentation, la calibration et Grad-CAM pour l‚Äôexplicabilit√©.

## Pipeline
1. **T√©l√©chargement des donn√©es** : Utilisation de la Kaggle API pour r√©cup√©rer le dataset (ex : HAM10000, Chest X-Ray Pneumonia, Fashion-MNIST).
2. **Pr√©traitement et augmentation** : Redimensionnement, flips, color jitter, normalisation.
3. **Chargement des donn√©es** : Organisation en train/val/test, DataLoader PyTorch.
4. **Mod√©lisation** : ResNet18/50 pr√©-entra√Æn√© ImageNet, fine-tuning des derniers blocs.
5. **Entra√Ænement** : Cross-entropy, Adam, early stopping, pond√©ration des classes.
6. **√âvaluation** : ROC-AUC, PR-AUC, F1, matrice de confusion, calibration.
7. **Explicabilit√©** : Visualisation Grad-CAM.

## Installation
- Python 3.10+
- PyTorch, torchvision, scikit-learn, matplotlib, seaborn, pytorch-grad-cam, kaggle

```bash
pip install torch torchvision scikit-learn matplotlib seaborn pytorch-grad-cam kaggle
```

## Ex√©cution
1. T√©l√©charger le dataset via Kaggle et organiser les dossiers `data/train`, `data/val`, `data/test`.
2. Lancer le script d‚Äôentra√Ænement :
    ```bash
    python train.py
    ```
3. Lancer l‚Äôinf√©rence et la visualisation :
    ```bash
    python inference.py --image chemin/vers/image.jpg --checkpoint best_ft.pt
    ```

## Bonnes pratiques
- Reproductibilit√© (seeds, versions, requirements.txt)
- Early stopping pour √©viter l‚Äôoverfitting
- Pond√©ration des classes pour le d√©s√©quilibre
- Data augmentation
- Calibration des probabilit√©s
- Explicabilit√© via Grad-CAM

## Extensions possibles
- Validation crois√©e K-fold
- Test Time Augmentation (TTA)
- Ensemble methods
- Calibration isotone
- D√©ploiement (ONNX, FastAPI, Docker)

## Auteur
Aldiouma Mbaye - MSc Data Engineer, Machine Learning
GitHub : afoumalorian-cmd

¬© 2025 - ECE Paris
‚îÇ   ‚îú‚îÄ‚îÄ config.json      # Configuration d'entra√Ænement
‚îÇ   ‚îî‚îÄ‚îÄ results/         # Visualisations
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ train.py         # Script d'entra√Ænement
‚îÇ   ‚îú‚îÄ‚îÄ inference.py     # Script d'inf√©rence
‚îÇ   ‚îî‚îÄ‚îÄ prepare_data.py  # Pr√©paration du dataset
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ data.py          # Chargement et augmentation
‚îÇ   ‚îú‚îÄ‚îÄ models.py        # Construction du mod√®le
‚îÇ   ‚îú‚îÄ‚îÄ training.py      # Boucle d'entra√Ænement
‚îÇ   ‚îú‚îÄ‚îÄ evaluation.py    # √âvaluation et m√©triques
‚îÇ   ‚îî‚îÄ‚îÄ gradcam.py       # Grad-CAM explicabilit√©
‚îú‚îÄ‚îÄ requirements.txt     # D√©pendances Python
‚îú‚îÄ‚îÄ README.md            # Cette documentation
‚îî‚îÄ‚îÄ notebook.ipynb       # Notebook Colab ex√©cutable
```

## üöÄ Installation

### 1. Cloner le d√©p√¥t
```bash
git clone <repository-url>
cd medical-imaging-classification
```

### 2. Cr√©er un environnement virtuel
```bash
# Python 3.8+
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

### 3. Installer les d√©pendances
```bash
pip install -r requirements.txt
```

## üìñ Utilisation

### Entra√Ænement du mod√®le

#### Configuration par d√©faut
```bash
python scripts/train.py \
    --data-root ./data \
    --model resnet18 \
    --epochs 20 \
    --batch-size 64 \
    --lr 1e-3
```

#### Avec options avanc√©es
```bash
python scripts/train.py \
    --model resnet50 \
    --num-classes 7 \
    --epochs 30 \
    --batch-size 32 \
    --lr 1e-3 \
    --fine-tune-epochs 15 \
    --ft-lr 5e-4 \
    --patience 4 \
    --seed 42 \
    --output-dir ./outputs
```

#### Options disponibles
```
--data-root          Racine du dataset (d√©faut: ./data)
--img-size           Taille des images (d√©faut: 224)
--batch-size         Taille des batches (d√©faut: 64)
--num-workers        Workers DataLoader (d√©faut: 2)
--model              Architecture (resnet18 | resnet50)
--num-classes        Nombre de classes (d√©faut: 7)
--epochs             Epochs d'entra√Ænement (d√©faut: 20)
--lr                 Learning rate initial (d√©faut: 1e-3)
--weight-decay       Weight decay (d√©faut: 1e-4)
--dropout            Dropout rate (d√©faut: 0.2)
--patience           Early stopping patience (d√©faut: 3)
--fine-tune-epochs   Epochs de fine-tuning (d√©faut: 10)
--ft-lr              LR fine-tuning (d√©faut: 5e-4)
--device             Device (auto | cpu | cuda)
--seed               Random seed (d√©faut: 42)
--output-dir         R√©pertoire de sortie (d√©faut: ./outputs)
```

### Inf√©rence et √©valuation

#### Sur une image unique
```bash
python scripts/inference.py \
    --image path/to/image.jpg \
    --checkpoint ./outputs/checkpoints/best_ft.pt \
    --gradcam
```

#### Sur l'ensemble de test
```bash
python scripts/inference.py \
    --test-dir ./data/test \
    --checkpoint ./outputs/checkpoints/best_ft.pt
```

## üî¨ M√©thodologie

### 1. Pr√©traitement et Augmentation

**Augmentations d'entra√Ænement:**
- RandomResizedCrop(224, scale=(0.7, 1.0))
- RandomHorizontalFlip(p=0.5)
- RandomVerticalFlip(p=0.3)
- ColorJitter(brightness, contrast, saturation, hue)
- RandomRotation(15¬∞)

**Normalisation ImageNet:**
```
mean=[0.485, 0.456, 0.406]
std=[0.229, 0.224, 0.225]
```

### 2. Transfer Learning

**Stage 1 - Formation de la t√™te de classification:**
- Mod√®le ResNet18/50 pr√©-entra√Æn√© sur ImageNet
- Backbone compl√®tement gel√© (requires_grad=False)
- Entra√Ænement de la couche FC uniquement
- Loss: CrossEntropyLoss avec poids de classe
- Optimizer: Adam(lr=1e-3)
- Scheduler: CosineAnnealingLR

**Stage 2 - Fine-tuning:**
- D√©cong√©lation de layer4 (derniers blocs r√©siduels)
- Entra√Ænement conjoint du backbone et de la t√™te
- LR r√©duite (5e-4) pour √©viter la d√©gradation
- Early stopping avec patience=2

### 3. Gestion du d√©s√©quilibre

**Pond√©rations de classe:**
```python
class_weights = 1.0 / class_counts
class_weights = class_weights / class_weights.sum() * num_classes
criterion = CrossEntropyLoss(weight=class_weights)
```

**Strat√©gies suppl√©mentaires:**
- Data augmentation agressive
- Dropout(0.2)
- Early stopping
- Stratified splitting

### 4. √âvaluation

**M√©triques calcul:**
- **Accuracy:** (TP + TN) / (TP + TN + FP + FN)
- **Precision:** TP / (TP + FP)
- **Recall:** TP / (TP + FN)
- **F1-Score:** 2 √ó (Precision √ó Recall) / (Precision + Recall)
- **ROC-AUC:** Aire sous la courbe ROC
- **PR-AUC:** Aire sous la courbe Precision-Recall
- **Confusion Matrix:** Matrice de confusion compl√®te

**Calibration:**
- Courbe de calibration (Platt)
- ECE (Expected Calibration Error)
- MCE (Maximum Calibration Error)

### 5. Explicabilit√© - Grad-CAM

**Grad-CAM (Gradient-weighted Class Activation Mapping):**
- Visualise les r√©gions de l'image influencant la pr√©diction
- Bas√© sur les gradients de la classe pr√©dite par rapport aux feature maps
- Layer cible: layer4 (derniers blocs r√©siduels)

```python
from src.gradcam import GradCAMExplainer

explainer = GradCAMExplainer(model, device)
vis, cam = explainer.visualize(image_tensor, target_class)
explainer.plot_gradcam(image_tensor, target_class)
```

## üìä R√©sultats attendus

### HAM10000 (7 classes)
| M√©trique | ResNet18 | ResNet50 |
|----------|----------|----------|
| Accuracy | ~75-80% | ~80-85% |
| F1-Score | ~0.75 | ~0.81 |
| ROC-AUC (OvR) | ~0.92 | ~0.94 |

*Note: R√©sultats d√©pendent de la stratification et du seed al√©atoire*

## üéì Bonnes pratiques impl√©ment√©es

### Reproductibilit√©
```python
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed_all(SEED)
torch.backends.cudnn.deterministic = True
os.environ['PYTHONHASHSEED'] = str(SEED)
```

### Gestion des versions
- `requirements.txt` avec versions √©pingl√©es
- Configuration JSON sauvegard√©e avec les r√©sultats
- Checkpoints du meilleur mod√®le

### Documentation
- Docstrings complets (Google style)
- Commentaires expliquant la logique m√©tier
- README d√©taill√©
- Notebook Colab ex√©cutable

### Tests et validation
- Early stopping pour √©viter l'overfitting
- Validation sur set distinct
- Test final sur set tenu √† l'√©cart
- Monitoring de m√©triques multiples

## ‚ö†Ô∏è Limitations et risques d'overfitting

1. **Taille du dataset:** HAM10000 contient ~10k images, potentiellement insuffisant pour certains mod√®les
2. **Biais g√©ographique/d√©mographique:** Provenance limit√©e des images
3. **Imbalance:** Certaines classes bien moins repr√©sent√©es
4. **Distribution shift:** Performance en production peut diff√©rer
5. **Grad-CAM:** Visualisations peuvent √™tre trompeuses - ne pas en d√©pendre seul

**Mitigations:**
- Data augmentation agressive
- Stratification train/val/test
- Class weighting
- Early stopping
- Validation crois√©e (bonus)
- Analyse d'erreurs qualitatives

## üîê Consid√©rations √©thiques

- ‚ö†Ô∏è **Ne pas utiliser en diagnostique clinique direct** - usage recherche uniquement
- **Consentement/Anonymisation:** Donn√©es m√©dicales n√©cessitent conformit√© RGPD/HIPAA
- **Biais d√©tection:** Mod√®les peuvent perpetuer biais existants
- **Explainabilit√©:** Grad-CAM ne remplace pas l'expertise m√©dicale
- **Audit r√©gulier:** Tester r√©guli√®rement sur donn√©es de groupes sous-repr√©sent√©s

## üìö Extensions / Am√©liorations futures

### Architectures
- [ ] EfficientNet, ViT (Vision Transformer)
- [ ] Ensemble methods (bagging, stacking)
- [ ] Knowledge distillation pour d√©ploiement

### Techniques
- [ ] Test Time Augmentation (TTA)
- [ ] Mixup / Cutmix data augmentation
- [ ] Label smoothing
- [ ] Calibration isotone
- [ ] Focal loss pour d√©s√©quilibre extr√™me

### √âvaluation avanc√©e
- [ ] Validation crois√©e K-fold
- [ ] Courbes d'apprentissage
- [ ] Analyse d'erreurs par classe
- [ ] Robustness tests (corruption, adversarial)

### D√©ploiement
- [ ] ONNX export
- [ ] FastAPI inference server
- [ ] Docker containerization
- [ ] CI/CD pipeline

## üìñ R√©f√©rences

- [ResNet Paper](https://arxiv.org/abs/1512.03385)
- [Transfer Learning Best Practices](https://cs231n.github.io/transfer-learning/)
- [Grad-CAM](https://arxiv.org/abs/1610.02055)
- [HAM10000 Dataset](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T)
- [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)

## üìù Licence

MIT License - Voir LICENSE file

## üë®‚Äçüíº Auteur

Aldiouma Mbaye - MSc Data Engineer, Machine Learning
ECE Paris, 2025

---

**Derni√®re mise √† jour:** December 4, 2025
